{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB,BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier,XGBRegressor\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score, recall_score, f1_score, precision_score,confusion_matrix, classification_report\n",
    "from sklearn.model_selection import GridSearchCV,cross_val_score,cross_val_predict\n",
    "import sklearn.model_selection as ms\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 导入数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('./cancer-data.csv')\n",
    "data=data.drop(['Unnamed: 0'],axis=1)\n",
    "X=data.drop(['Group'],axis=1)\n",
    "y=data['Group']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 数据归一化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "column=X.columns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X=sc.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 划分训练集测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape : (128, 202)\n",
      "Test shape: (33, 202)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42,stratify=None)\n",
    "print(f'Train shape : {X_train.shape}\\nTest shape: {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crosspredict(estimator,Xtrain,ytrain,cv):\n",
    "    print(\"cross-validate across the entire data set\")\n",
    "    y_pred_cross=cross_val_predict(estimator,Xtrain,ytrain,cv=cv)\n",
    "    confusion_cross=confusion_matrix(ytrain,y_pred_cross)\n",
    "    a=accuracy_score(ytrain,y_pred_cross)\n",
    "    p=precision_score(ytrain, y_pred_cross)\n",
    "    r=recall_score(ytrain, y_pred_cross)\n",
    "    f1=f1_score(ytrain, y_pred_cross)\n",
    "    wf1=f1_score(ytrain, y_pred_cross, average='weighted')\n",
    "    #auc=roc_auc_score(ytrain,estimator.predict_proba(Xtrain)[:,1])\n",
    "    print('the confusion_matrix of the model is : \\n',confusion_cross)\n",
    "    print('the accuracy of the model is : ',a)\n",
    "    print(\"the precision score of the model is : \", p)\n",
    "    print(\"the recall score of the model is :\", r)\n",
    "    print('the f1_score of the model  is :',f1)\n",
    "    print('the weighted_f1 of the model is :',wf1)\n",
    "    print('the classification_report is :\\n',classification_report(ytrain, y_pred_cross,digits=4))\n",
    "    #print('the auc is :',auc)\n",
    "    return a,p,r,f1,wf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#只在测试集上测试\n",
    "def testpredict(estimator,Xtrain,ytrain,Xtest,ytest):\n",
    "    print(\"只在测试集上测试\")\n",
    "    model=estimator.fit(Xtrain,ytrain)\n",
    "    y_pred_train=model.predict(Xtrain)\n",
    "    y_pred_test=model.predict(Xtest)\n",
    "    confusion=confusion_matrix(ytest,y_pred_test)\n",
    "    acc=accuracy_score(ytest, y_pred_test)\n",
    "    rec=recall_score(ytest, y_pred_test)\n",
    "    pre=precision_score(ytest, y_pred_test)\n",
    "    f1=f1_score(ytest, y_pred_test)\n",
    "    print('the confusion_matrix of the model is : \\n',confusion)\n",
    "    print('the accuracy of the model on testing set is ：',acc)\n",
    "    print(\"the precision score of the model on testing set is : \",pre )\n",
    "    print(\"the recall score of the model on testing set is :\", rec)\n",
    "    print('the f1_score of the model on testing set is :',f1)\n",
    "    \n",
    "    return acc,pre,rec,f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier(),KNeighborsClassifier(),SVC(),AdaBoostClassifier(),\n",
    "   #### LogisticRegression(),GradientBoostingClassifier(),XGBClassifier(),DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=[RandomForestClassifier(),KNeighborsClassifier(),SVC(),AdaBoostClassifier(),\n",
    "       LogisticRegression(),GradientBoostingClassifier(),XGBClassifier(),DecisionTreeClassifier()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model is : RandomForestClassifier()\n",
      "只在测试集上测试\n",
      "the confusion_matrix of the model is : \n",
      " [[12  3]\n",
      " [ 7 11]]\n",
      "the accuracy of the model on testing set is ： 0.696969696969697\n",
      "the precision score of the model on testing set is :  0.7857142857142857\n",
      "the recall score of the model on testing set is : 0.6111111111111112\n",
      "the f1_score of the model on testing set is : 0.6875000000000001\n",
      "the model is : RandomForestClassifier()\n",
      "cross-validate across the entire data set\n",
      "the confusion_matrix of the model is : \n",
      " [[52 23]\n",
      " [32 54]]\n",
      "the accuracy of the model is :  0.6583850931677019\n",
      "the precision score of the model is :  0.7012987012987013\n",
      "the recall score of the model is : 0.627906976744186\n",
      "the f1_score of the model  is : 0.6625766871165645\n",
      "the weighted_f1 of the model is : 0.6586223532025433\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6190    0.6933    0.6541        75\n",
      "           1     0.7013    0.6279    0.6626        86\n",
      "\n",
      "    accuracy                         0.6584       161\n",
      "   macro avg     0.6602    0.6606    0.6583       161\n",
      "weighted avg     0.6630    0.6584    0.6586       161\n",
      "\n",
      "\n",
      "\n",
      "the model is : KNeighborsClassifier()\n",
      "只在测试集上测试\n",
      "the confusion_matrix of the model is : \n",
      " [[12  3]\n",
      " [ 9  9]]\n",
      "the accuracy of the model on testing set is ： 0.6363636363636364\n",
      "the precision score of the model on testing set is :  0.75\n",
      "the recall score of the model on testing set is : 0.5\n",
      "the f1_score of the model on testing set is : 0.6\n",
      "the model is : KNeighborsClassifier()\n",
      "cross-validate across the entire data set\n",
      "the confusion_matrix of the model is : \n",
      " [[53 22]\n",
      " [42 44]]\n",
      "the accuracy of the model is :  0.6024844720496895\n",
      "the precision score of the model is :  0.6666666666666666\n",
      "the recall score of the model is : 0.5116279069767442\n",
      "the f1_score of the model  is : 0.5789473684210527\n",
      "the weighted_f1 of the model is : 0.5997154010345558\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5579    0.7067    0.6235        75\n",
      "           1     0.6667    0.5116    0.5789        86\n",
      "\n",
      "    accuracy                         0.6025       161\n",
      "   macro avg     0.6123    0.6091    0.6012       161\n",
      "weighted avg     0.6160    0.6025    0.5997       161\n",
      "\n",
      "\n",
      "\n",
      "the model is : SVC()\n",
      "只在测试集上测试\n",
      "the confusion_matrix of the model is : \n",
      " [[12  3]\n",
      " [ 6 12]]\n",
      "the accuracy of the model on testing set is ： 0.7272727272727273\n",
      "the precision score of the model on testing set is :  0.8\n",
      "the recall score of the model on testing set is : 0.6666666666666666\n",
      "the f1_score of the model on testing set is : 0.7272727272727272\n",
      "the model is : SVC()\n",
      "cross-validate across the entire data set\n",
      "the confusion_matrix of the model is : \n",
      " [[59 16]\n",
      " [34 52]]\n",
      "the accuracy of the model is :  0.6894409937888198\n",
      "the precision score of the model is :  0.7647058823529411\n",
      "the recall score of the model is : 0.6046511627906976\n",
      "the f1_score of the model  is : 0.6753246753246753\n",
      "the weighted_f1 of the model is : 0.687928531096233\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6344    0.7867    0.7024        75\n",
      "           1     0.7647    0.6047    0.6753        86\n",
      "\n",
      "    accuracy                         0.6894       161\n",
      "   macro avg     0.6996    0.6957    0.6889       161\n",
      "weighted avg     0.7040    0.6894    0.6879       161\n",
      "\n",
      "\n",
      "\n",
      "the model is : AdaBoostClassifier()\n",
      "只在测试集上测试\n",
      "the confusion_matrix of the model is : \n",
      " [[12  3]\n",
      " [ 3 15]]\n",
      "the accuracy of the model on testing set is ： 0.8181818181818182\n",
      "the precision score of the model on testing set is :  0.8333333333333334\n",
      "the recall score of the model on testing set is : 0.8333333333333334\n",
      "the f1_score of the model on testing set is : 0.8333333333333334\n",
      "the model is : AdaBoostClassifier()\n",
      "cross-validate across the entire data set\n",
      "the confusion_matrix of the model is : \n",
      " [[59 16]\n",
      " [22 64]]\n",
      "the accuracy of the model is :  0.7639751552795031\n",
      "the precision score of the model is :  0.8\n",
      "the recall score of the model is : 0.7441860465116279\n",
      "the f1_score of the model  is : 0.7710843373493975\n",
      "the weighted_f1 of the model is : 0.7642485853591144\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7284    0.7867    0.7564        75\n",
      "           1     0.8000    0.7442    0.7711        86\n",
      "\n",
      "    accuracy                         0.7640       161\n",
      "   macro avg     0.7642    0.7654    0.7637       161\n",
      "weighted avg     0.7666    0.7640    0.7642       161\n",
      "\n",
      "\n",
      "\n",
      "the model is : BernoulliNB()\n",
      "只在测试集上测试\n",
      "the confusion_matrix of the model is : \n",
      " [[13  2]\n",
      " [ 7 11]]\n",
      "the accuracy of the model on testing set is ： 0.7272727272727273\n",
      "the precision score of the model on testing set is :  0.8461538461538461\n",
      "the recall score of the model on testing set is : 0.6111111111111112\n",
      "the f1_score of the model on testing set is : 0.7096774193548387\n",
      "the model is : BernoulliNB()\n",
      "cross-validate across the entire data set\n",
      "the confusion_matrix of the model is : \n",
      " [[57 18]\n",
      " [41 45]]\n",
      "the accuracy of the model is :  0.6335403726708074\n",
      "the precision score of the model is :  0.7142857142857143\n",
      "the recall score of the model is : 0.5232558139534884\n",
      "the f1_score of the model  is : 0.6040268456375839\n",
      "the weighted_f1 of the model is : 0.6296166089611882\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5816    0.7600    0.6590        75\n",
      "           1     0.7143    0.5233    0.6040        86\n",
      "\n",
      "    accuracy                         0.6335       161\n",
      "   macro avg     0.6480    0.6416    0.6315       161\n",
      "weighted avg     0.6525    0.6335    0.6296       161\n",
      "\n",
      "\n",
      "\n",
      "the model is : LogisticRegression()\n",
      "只在测试集上测试\n",
      "the confusion_matrix of the model is : \n",
      " [[13  2]\n",
      " [ 3 15]]\n",
      "the accuracy of the model on testing set is ： 0.8484848484848485\n",
      "the precision score of the model on testing set is :  0.8823529411764706\n",
      "the recall score of the model on testing set is : 0.8333333333333334\n",
      "the f1_score of the model on testing set is : 0.8571428571428571\n",
      "the model is : LogisticRegression()\n",
      "cross-validate across the entire data set\n",
      "the confusion_matrix of the model is : \n",
      " [[49 26]\n",
      " [25 61]]\n",
      "the accuracy of the model is :  0.6832298136645962\n",
      "the precision score of the model is :  0.7011494252873564\n",
      "the recall score of the model is : 0.7093023255813954\n",
      "the f1_score of the model  is : 0.7052023121387283\n",
      "the weighted_f1 of the model is : 0.6830823472318839\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6622    0.6533    0.6577        75\n",
      "           1     0.7011    0.7093    0.7052        86\n",
      "\n",
      "    accuracy                         0.6832       161\n",
      "   macro avg     0.6817    0.6813    0.6815       161\n",
      "weighted avg     0.6830    0.6832    0.6831       161\n",
      "\n",
      "\n",
      "\n",
      "the model is : GradientBoostingClassifier()\n",
      "只在测试集上测试\n",
      "the confusion_matrix of the model is : \n",
      " [[13  2]\n",
      " [ 5 13]]\n",
      "the accuracy of the model on testing set is ： 0.7878787878787878\n",
      "the precision score of the model on testing set is :  0.8666666666666667\n",
      "the recall score of the model on testing set is : 0.7222222222222222\n",
      "the f1_score of the model on testing set is : 0.7878787878787877\n",
      "the model is : GradientBoostingClassifier()\n",
      "cross-validate across the entire data set\n",
      "the confusion_matrix of the model is : \n",
      " [[54 21]\n",
      " [24 62]]\n",
      "the accuracy of the model is :  0.7204968944099379\n",
      "the precision score of the model is :  0.7469879518072289\n",
      "the recall score of the model is : 0.7209302325581395\n",
      "the f1_score of the model  is : 0.7337278106508875\n",
      "the weighted_f1 of the model is : 0.7207563241401526\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6923    0.7200    0.7059        75\n",
      "           1     0.7470    0.7209    0.7337        86\n",
      "\n",
      "    accuracy                         0.7205       161\n",
      "   macro avg     0.7196    0.7205    0.7198       161\n",
      "weighted avg     0.7215    0.7205    0.7208       161\n",
      "\n",
      "\n",
      "\n",
      "the model is : XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "只在测试集上测试\n",
      "the confusion_matrix of the model is : \n",
      " [[10  5]\n",
      " [ 2 16]]\n",
      "the accuracy of the model on testing set is ： 0.7878787878787878\n",
      "the precision score of the model on testing set is :  0.7619047619047619\n",
      "the recall score of the model on testing set is : 0.8888888888888888\n",
      "the f1_score of the model on testing set is : 0.8205128205128205\n",
      "the model is : XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "cross-validate across the entire data set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the confusion_matrix of the model is : \n",
      " [[47 28]\n",
      " [28 58]]\n",
      "the accuracy of the model is :  0.6521739130434783\n",
      "the precision score of the model is :  0.6744186046511628\n",
      "the recall score of the model is : 0.6744186046511628\n",
      "the f1_score of the model  is : 0.6744186046511628\n",
      "the weighted_f1 of the model is : 0.6521739130434783\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6267    0.6267    0.6267        75\n",
      "           1     0.6744    0.6744    0.6744        86\n",
      "\n",
      "    accuracy                         0.6522       161\n",
      "   macro avg     0.6505    0.6505    0.6505       161\n",
      "weighted avg     0.6522    0.6522    0.6522       161\n",
      "\n",
      "\n",
      "\n",
      "the model is : DecisionTreeClassifier()\n",
      "只在测试集上测试\n",
      "the confusion_matrix of the model is : \n",
      " [[10  5]\n",
      " [ 7 11]]\n",
      "the accuracy of the model on testing set is ： 0.6363636363636364\n",
      "the precision score of the model on testing set is :  0.6875\n",
      "the recall score of the model on testing set is : 0.6111111111111112\n",
      "the f1_score of the model on testing set is : 0.6470588235294118\n",
      "the model is : DecisionTreeClassifier()\n",
      "cross-validate across the entire data set\n",
      "the confusion_matrix of the model is : \n",
      " [[46 29]\n",
      " [25 61]]\n",
      "the accuracy of the model is :  0.6645962732919255\n",
      "the precision score of the model is :  0.6777777777777778\n",
      "the recall score of the model is : 0.7093023255813954\n",
      "the f1_score of the model  is : 0.6931818181818181\n",
      "the weighted_f1 of the model is : 0.6638131076785038\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6479    0.6133    0.6301        75\n",
      "           1     0.6778    0.7093    0.6932        86\n",
      "\n",
      "    accuracy                         0.6646       161\n",
      "   macro avg     0.6628    0.6613    0.6617       161\n",
      "weighted avg     0.6639    0.6646    0.6638       161\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(model)):\n",
    "    print(\"the model is :\",model[i])\n",
    "    f1_test_before=testpredict(model[i],X_train,y_train,X_test,y_test)\n",
    "    print(\"the model is :\",model[i])\n",
    "    f1_cross_before=crosspredict(model[i],X,y,10)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网格搜索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Grid Search\n",
    "def gridsearch(params,estimator,Xtrain,ytrain,cvnumber):\n",
    "    model = ms.GridSearchCV(estimator, params, cv=cvnumber)\n",
    "    model.fit(Xtrain, ytrain)\n",
    "    print(\"the best_params of the model is:\",model.best_params_)\n",
    "    print(\"the best_score of the model is:\",model.best_score_)\n",
    "    print(\"the best_estimator of the model is:\",model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best_params of the model is: {'C': 10, 'coef0': 1, 'degree': 3, 'kernel': 'poly'}\n",
      "the best_score of the model is: 0.666025641025641\n",
      "the best_estimator of the model is: SVC(C=10, coef0=1, kernel='poly', probability=True)\n"
     ]
    }
   ],
   "source": [
    "## svm\n",
    "params = [\n",
    "    {'kernel':['linear'], 'C':[1, 10, 100, 1000]},\n",
    "    {'kernel':['poly'], 'C':[1,10,100], 'degree':[2, 3,4,5],'coef0':[0,1,10,100]}, \n",
    "    {'kernel':['rbf'], 'C':[1,10,100], 'gamma':[1, 0.1, 0.01]}]\n",
    "gridsearch(params,SVC(probability=True),X_train,y_train,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best_params of the RF model is: {'max_depth': 4, 'n_estimators': 7}\n",
      "the best_score of the RF model is: 0.7108974358974358\n",
      "the best_estimator of the RF model is: RandomForestClassifier(max_depth=4, n_estimators=7)\n"
     ]
    }
   ],
   "source": [
    "#RF\n",
    "params={\n",
    "    'n_estimators':np.arange(1,21,1),\n",
    "    'max_depth': np.arange(1,21,1),\n",
    "}\n",
    "model = ms.GridSearchCV(RandomForestClassifier(), params, cv=10)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"the best_params of the RF model is:\",model.best_params_)\n",
    "# 获取最优得分\n",
    "print(\"the best_score of the RF model is:\",model.best_score_)\n",
    "# 获取最优模型的信息\n",
    "print(\"the best_estimator of the RF model is:\",model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best_params of the RF model is: {'n_estimators': 20}\n",
      "the best_score of the RF model is: 0.7025641025641026\n",
      "the best_estimator of the RF model is: RandomForestClassifier(n_estimators=20, n_jobs=-1, random_state=90)\n"
     ]
    }
   ],
   "source": [
    "#RF\n",
    "params={\n",
    "    'n_estimators':np.arange(1,201,1),\n",
    "#     'max_depth': np.arange(1,20,1),\n",
    "}\n",
    "model = ms.GridSearchCV(RandomForestClassifier(n_jobs=-1,random_state=90), params, cv=10)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"the best_params of the RF model is:\",model.best_params_)\n",
    "# 获取最优得分\n",
    "print(\"the best_score of the RF model is:\",model.best_score_)\n",
    "# 获取最优模型的信息\n",
    "print(\"the best_estimator of the RF model is:\",model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best_params of the RF model is: {'max_depth': 2}\n",
      "the best_score of the RF model is: 0.6557692307692308\n",
      "the best_estimator of the RF model is: RandomForestClassifier(max_depth=2, n_estimators=105, n_jobs=-1,\n",
      "                       random_state=90)\n"
     ]
    }
   ],
   "source": [
    "#RF\n",
    "params={\n",
    "#     'n_estimators':np.arange(1,201,1),\n",
    "     'max_depth': np.arange(1,20,1),\n",
    "}\n",
    "model = ms.GridSearchCV(RandomForestClassifier(n_estimators=105, n_jobs=-1,random_state=90), params, cv=10)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"the best_params of the RF model is:\",model.best_params_)\n",
    "# 获取最优得分\n",
    "print(\"the best_score of the RF model is:\",model.best_score_)\n",
    "# 获取最优模型的信息\n",
    "print(\"the best_estimator of the RF model is:\",model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best_params of the model is: {'n_neighbors': 11}\n",
      "the best_score of the model is: 0.6576923076923077\n",
      "the best_estimator of the model is: KNeighborsClassifier(n_neighbors=11)\n"
     ]
    }
   ],
   "source": [
    "#KNN\n",
    "params={\n",
    "    'n_neighbors':np.arange(2,101,1)\n",
    "} \n",
    "gridsearch(params,KNeighborsClassifier(),X_train, y_train,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best_params of the AdaBoost model is: {'learning_rate': 0.1, 'n_estimators': 100}\n",
      "the best_score of the AdaBoost model is: 0.726923076923077\n",
      "the best_estimator of the AdaBoost model is: AdaBoostClassifier(learning_rate=0.1, n_estimators=100)\n"
     ]
    }
   ],
   "source": [
    "#AdaBoost\n",
    "params={\n",
    "    'n_estimators':[10,50,100,200,300,400,500],\n",
    "    'learning_rate':[0.0001,0.001,0.01,0.1,1]\n",
    "}\n",
    "model = ms.GridSearchCV(AdaBoostClassifier(), params, cv=10)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "print(\"the best_params of the AdaBoost model is:\",model.best_params_)\n",
    "# 获取最优得分\n",
    "print(\"the best_score of the AdaBoost model is:\",model.best_score_)\n",
    "# 获取最优模型的信息\n",
    "print(\"the best_estimator of the AdaBoost model is:\",model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best_params of the LogisticRegression model is: {'C': 0.001, 'max_iter': 100}\n",
      "the best_score of the LogisticRegression model is: 0.6403846153846154\n",
      "the best_estimator of the LogisticRegression model is: LogisticRegression(C=0.001)\n"
     ]
    }
   ],
   "source": [
    "#LR\n",
    "params={\n",
    "    'C':[0.0001,0.001,0.01,0.1],\n",
    "    'max_iter':[100,200,300,400,500]\n",
    "}\n",
    "model = ms.GridSearchCV(LogisticRegression(), params, cv=10)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"the best_params of the LogisticRegression model is:\",model.best_params_)\n",
    "# 获取最优得分\n",
    "print(\"the best_score of the LogisticRegression model is:\",model.best_score_)\n",
    "# 获取最优模型的信息\n",
    "print(\"the best_estimator of the LogisticRegression model is:\",model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best_params of the GradientBoost model is: {'learning_rate': 1, 'loss': 'deviance', 'n_estimators': 50}\n",
      "the best_score of the GradientBoost model is: 0.6711538461538462\n",
      "the best_estimator of the GradientBoost model is: GradientBoostingClassifier(learning_rate=1, n_estimators=50)\n"
     ]
    }
   ],
   "source": [
    "#Gradient Boosting\n",
    "params={\n",
    "    'loss':['deviance','exponential'],\n",
    "    'n_estimators':[10,50,100,200,300,400,500],\n",
    "    'learning_rate':[0.0001,0.001,0.01,0.1,1]\n",
    "}\n",
    "model = ms.GridSearchCV(GradientBoostingClassifier(), params, cv=10)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"the best_params of the GradientBoost model is:\",model.best_params_)\n",
    "# 获取最优得分\n",
    "print(\"the best_score of the GradientBoost model is:\",model.best_score_)\n",
    "# 获取最优模型的信息\n",
    "print(\"the best_estimator of the GradientBoost model is:\",model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best_params of the XGBoost model is: {'booster': 'gblinear', 'learning_rate': 0.0001, 'max_depth': 5, 'n_estimators': 300}\n",
      "the best_score of the XGBoost model is: 0.6416666666666667\n",
      "the best_estimator of the XGBoost model is: XGBClassifier(base_score=None, booster='gblinear', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.0001, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n"
     ]
    }
   ],
   "source": [
    "#XGBoost\n",
    "params={\n",
    "    'booster':['gbtree','gblinear'],\n",
    "    'n_estimators':[10,50,100,200,300,400,500,1000,2000],\n",
    "    'learning_rate':[0.0001,0.001,0.01,0.05,0.1,0.3,1],\n",
    "    'max_depth': [5, 10, 15, 20, 25]\n",
    "}\n",
    "model = ms.GridSearchCV(XGBClassifier(), params, cv=10)\n",
    "model.fit(X_train, y_train)\n",
    "print(\"the best_params of the XGBoost model is:\",model.best_params_)\n",
    "# 获取最优得分\n",
    "print(\"the best_score of the XGBoost model is:\",model.best_score_)\n",
    "# 获取最优模型的信息\n",
    "print(\"the best_estimator of the XGBoost model is:\",model.best_estimator_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the best_params of the model is: {'max_depth': 12, 'min_samples_leaf': 4, 'min_samples_split': 6}\n",
      "the best_score of the model is: 0.633974358974359\n",
      "the best_estimator of the model is: DecisionTreeClassifier(max_depth=12, min_samples_leaf=4, min_samples_split=6)\n"
     ]
    }
   ],
   "source": [
    "#decisiontree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "params={\n",
    "    'max_depth':list((5,10,12)),\n",
    "    'min_samples_split': list((2,4,6)),\n",
    "    'min_samples_leaf':list((1,2,4))\n",
    "}\n",
    "gridsearch(params,DecisionTreeClassifier(),X_train,y_train,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model comparasion after grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelgrid=[SVC(C=10, coef0=1, degree=3, kernel='poly', probability=True),\n",
    "       RandomForestClassifier(max_depth=2, n_estimators=105, n_jobs=-1,random_state=90),\n",
    "       KNeighborsClassifier(n_neighbors=11),\n",
    "       AdaBoostClassifier(learning_rate=0.1),\n",
    "       LogisticRegression(C=0.001),\n",
    "       GradientBoostingClassifier(loss='deviance', n_estimators=50),\n",
    "       XGBClassifier(booster='gblinear',learning_rate=0.0001,max_depth=5,n_estimators=300),\n",
    "       DecisionTreeClassifier(max_depth=12, min_samples_leaf=4, min_samples_split=6)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the model is : SVC(C=10, coef0=1, kernel='poly', probability=True)\n",
      "只在测试集上测试\n",
      "the confusion_matrix of the model is : \n",
      " [[13  2]\n",
      " [ 3 15]]\n",
      "the accuracy of the model on testing set is ： 0.8484848484848485\n",
      "the precision score of the model on testing set is :  0.8823529411764706\n",
      "the recall score of the model on testing set is : 0.8333333333333334\n",
      "the f1_score of the model on testing set is : 0.8571428571428571\n",
      "the model is : SVC(C=10, coef0=1, kernel='poly', probability=True)\n",
      "cross-validate across the entire data set\n",
      "the confusion_matrix of the model is : \n",
      " [[52 23]\n",
      " [32 54]]\n",
      "the accuracy of the model is :  0.6583850931677019\n",
      "the precision score of the model is :  0.7012987012987013\n",
      "the recall score of the model is : 0.627906976744186\n",
      "the f1_score of the model  is : 0.6625766871165645\n",
      "the weighted_f1 of the model is : 0.6586223532025433\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6190    0.6933    0.6541        75\n",
      "           1     0.7013    0.6279    0.6626        86\n",
      "\n",
      "    accuracy                         0.6584       161\n",
      "   macro avg     0.6602    0.6606    0.6583       161\n",
      "weighted avg     0.6630    0.6584    0.6586       161\n",
      "\n",
      "\n",
      "\n",
      "the model is : RandomForestClassifier(max_depth=2, n_estimators=105, n_jobs=-1,\n",
      "                       random_state=90)\n",
      "只在测试集上测试\n",
      "the confusion_matrix of the model is : \n",
      " [[10  5]\n",
      " [ 7 11]]\n",
      "the accuracy of the model on testing set is ： 0.6363636363636364\n",
      "the precision score of the model on testing set is :  0.6875\n",
      "the recall score of the model on testing set is : 0.6111111111111112\n",
      "the f1_score of the model on testing set is : 0.6470588235294118\n",
      "the model is : RandomForestClassifier(max_depth=2, n_estimators=105, n_jobs=-1,\n",
      "                       random_state=90)\n",
      "cross-validate across the entire data set\n",
      "the confusion_matrix of the model is : \n",
      " [[51 24]\n",
      " [36 50]]\n",
      "the accuracy of the model is :  0.6273291925465838\n",
      "the precision score of the model is :  0.6756756756756757\n",
      "the recall score of the model is : 0.5813953488372093\n",
      "the f1_score of the model  is : 0.6250000000000001\n",
      "the weighted_f1 of the model is : 0.6271566597653555\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5862    0.6800    0.6296        75\n",
      "           1     0.6757    0.5814    0.6250        86\n",
      "\n",
      "    accuracy                         0.6273       161\n",
      "   macro avg     0.6309    0.6307    0.6273       161\n",
      "weighted avg     0.6340    0.6273    0.6272       161\n",
      "\n",
      "\n",
      "\n",
      "the model is : KNeighborsClassifier(n_neighbors=11)\n",
      "只在测试集上测试\n",
      "the confusion_matrix of the model is : \n",
      " [[12  3]\n",
      " [ 8 10]]\n",
      "the accuracy of the model on testing set is ： 0.6666666666666666\n",
      "the precision score of the model on testing set is :  0.7692307692307693\n",
      "the recall score of the model on testing set is : 0.5555555555555556\n",
      "the f1_score of the model on testing set is : 0.6451612903225806\n",
      "the model is : KNeighborsClassifier(n_neighbors=11)\n",
      "cross-validate across the entire data set\n",
      "the confusion_matrix of the model is : \n",
      " [[56 19]\n",
      " [44 42]]\n",
      "the accuracy of the model is :  0.6086956521739131\n",
      "the precision score of the model is :  0.6885245901639344\n",
      "the recall score of the model is : 0.4883720930232558\n",
      "the f1_score of the model  is : 0.5714285714285714\n",
      "the weighted_f1 of the model is : 0.6033717834960071\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5600    0.7467    0.6400        75\n",
      "           1     0.6885    0.4884    0.5714        86\n",
      "\n",
      "    accuracy                         0.6087       161\n",
      "   macro avg     0.6243    0.6175    0.6057       161\n",
      "weighted avg     0.6287    0.6087    0.6034       161\n",
      "\n",
      "\n",
      "\n",
      "the model is : AdaBoostClassifier(learning_rate=0.1)\n",
      "只在测试集上测试\n",
      "the confusion_matrix of the model is : \n",
      " [[14  1]\n",
      " [ 6 12]]\n",
      "the accuracy of the model on testing set is ： 0.7878787878787878\n",
      "the precision score of the model on testing set is :  0.9230769230769231\n",
      "the recall score of the model on testing set is : 0.6666666666666666\n",
      "the f1_score of the model on testing set is : 0.7741935483870968\n",
      "the model is : AdaBoostClassifier(learning_rate=0.1)\n",
      "cross-validate across the entire data set\n",
      "the confusion_matrix of the model is : \n",
      " [[58 17]\n",
      " [23 63]]\n",
      "the accuracy of the model is :  0.7515527950310559\n",
      "the precision score of the model is :  0.7875\n",
      "the recall score of the model is : 0.7325581395348837\n",
      "the f1_score of the model  is : 0.7590361445783131\n",
      "the weighted_f1 of the model is : 0.7518406161674888\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7160    0.7733    0.7436        75\n",
      "           1     0.7875    0.7326    0.7590        86\n",
      "\n",
      "    accuracy                         0.7516       161\n",
      "   macro avg     0.7518    0.7529    0.7513       161\n",
      "weighted avg     0.7542    0.7516    0.7518       161\n",
      "\n",
      "\n",
      "\n",
      "the model is : LogisticRegression(C=0.001)\n",
      "只在测试集上测试\n",
      "the confusion_matrix of the model is : \n",
      " [[ 5 10]\n",
      " [ 4 14]]\n",
      "the accuracy of the model on testing set is ： 0.5757575757575758\n",
      "the precision score of the model on testing set is :  0.5833333333333334\n",
      "the recall score of the model on testing set is : 0.7777777777777778\n",
      "the f1_score of the model on testing set is : 0.6666666666666666\n",
      "the model is : LogisticRegression(C=0.001)\n",
      "cross-validate across the entire data set\n",
      "the confusion_matrix of the model is : \n",
      " [[39 36]\n",
      " [29 57]]\n",
      "the accuracy of the model is :  0.5962732919254659\n",
      "the precision score of the model is :  0.6129032258064516\n",
      "the recall score of the model is : 0.6627906976744186\n",
      "the f1_score of the model  is : 0.6368715083798883\n",
      "the weighted_f1 of the model is : 0.5942859666444801\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5735    0.5200    0.5455        75\n",
      "           1     0.6129    0.6628    0.6369        86\n",
      "\n",
      "    accuracy                         0.5963       161\n",
      "   macro avg     0.5932    0.5914    0.5912       161\n",
      "weighted avg     0.5946    0.5963    0.5943       161\n",
      "\n",
      "\n",
      "\n",
      "the model is : GradientBoostingClassifier(n_estimators=50)\n",
      "只在测试集上测试\n",
      "the confusion_matrix of the model is : \n",
      " [[13  2]\n",
      " [ 5 13]]\n",
      "the accuracy of the model on testing set is ： 0.7878787878787878\n",
      "the precision score of the model on testing set is :  0.8666666666666667\n",
      "the recall score of the model on testing set is : 0.7222222222222222\n",
      "the f1_score of the model on testing set is : 0.7878787878787877\n",
      "the model is : GradientBoostingClassifier(n_estimators=50)\n",
      "cross-validate across the entire data set\n",
      "the confusion_matrix of the model is : \n",
      " [[55 20]\n",
      " [27 59]]\n",
      "the accuracy of the model is :  0.7080745341614907\n",
      "the precision score of the model is :  0.7468354430379747\n",
      "the recall score of the model is : 0.686046511627907\n",
      "the f1_score of the model  is : 0.7151515151515152\n",
      "the weighted_f1 of the model is : 0.7083900683457593\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6707    0.7333    0.7006        75\n",
      "           1     0.7468    0.6860    0.7152        86\n",
      "\n",
      "    accuracy                         0.7081       161\n",
      "   macro avg     0.7088    0.7097    0.7079       161\n",
      "weighted avg     0.7114    0.7081    0.7084       161\n",
      "\n",
      "\n",
      "\n",
      "the model is : XGBClassifier(base_score=None, booster='gblinear', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.0001, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "只在测试集上测试\n",
      "the confusion_matrix of the model is : \n",
      " [[10  5]\n",
      " [ 6 12]]\n",
      "the accuracy of the model on testing set is ： 0.6666666666666666\n",
      "the precision score of the model on testing set is :  0.7058823529411765\n",
      "the recall score of the model on testing set is : 0.6666666666666666\n",
      "the f1_score of the model on testing set is : 0.6857142857142857\n",
      "the model is : XGBClassifier(base_score=None, booster='gblinear', callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.0001, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=5, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              multi_strategy=None, n_estimators=300, n_jobs=None,\n",
      "              num_parallel_tree=None, random_state=None, ...)\n",
      "cross-validate across the entire data set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the confusion_matrix of the model is : \n",
      " [[47 28]\n",
      " [32 54]]\n",
      "the accuracy of the model is :  0.6273291925465838\n",
      "the precision score of the model is :  0.6585365853658537\n",
      "the recall score of the model is : 0.627906976744186\n",
      "the f1_score of the model  is : 0.6428571428571429\n",
      "the weighted_f1 of the model is : 0.6277325159312738\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5949    0.6267    0.6104        75\n",
      "           1     0.6585    0.6279    0.6429        86\n",
      "\n",
      "    accuracy                         0.6273       161\n",
      "   macro avg     0.6267    0.6273    0.6266       161\n",
      "weighted avg     0.6289    0.6273    0.6277       161\n",
      "\n",
      "\n",
      "\n",
      "the model is : DecisionTreeClassifier(max_depth=12, min_samples_leaf=4, min_samples_split=6)\n",
      "只在测试集上测试\n",
      "the confusion_matrix of the model is : \n",
      " [[12  3]\n",
      " [ 9  9]]\n",
      "the accuracy of the model on testing set is ： 0.6363636363636364\n",
      "the precision score of the model on testing set is :  0.75\n",
      "the recall score of the model on testing set is : 0.5\n",
      "the f1_score of the model on testing set is : 0.6\n",
      "the model is : DecisionTreeClassifier(max_depth=12, min_samples_leaf=4, min_samples_split=6)\n",
      "cross-validate across the entire data set\n",
      "the confusion_matrix of the model is : \n",
      " [[52 23]\n",
      " [26 60]]\n",
      "the accuracy of the model is :  0.6956521739130435\n",
      "the precision score of the model is :  0.7228915662650602\n",
      "the recall score of the model is : 0.6976744186046512\n",
      "the f1_score of the model  is : 0.7100591715976331\n",
      "the weighted_f1 of the model is : 0.6959346640637217\n",
      "the classification_report is :\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6667    0.6933    0.6797        75\n",
      "           1     0.7229    0.6977    0.7101        86\n",
      "\n",
      "    accuracy                         0.6957       161\n",
      "   macro avg     0.6948    0.6955    0.6949       161\n",
      "weighted avg     0.6967    0.6957    0.6959       161\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(modelgrid)):\n",
    "    print(\"the model is :\",modelgrid[i])\n",
    "    f1_test_before=testpredict(modelgrid[i],X_train,y_train,X_test,y_test)\n",
    "    print(\"the model is :\",modelgrid[i])\n",
    "    f1_cross_before=crosspredict(modelgrid[i],X,y,10)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
